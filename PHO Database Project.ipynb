{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHO Database Project\n",
    "\n",
    "### Background\n",
    "\n",
    "* Monthly Master Medical Staff (MMS) list comes out;\n",
    "* Craig manually adds any new providers to the CIN database;\n",
    "* It's frustrating & error-prone; we want this to be easier\n",
    "\n",
    "### What We Want\n",
    "\n",
    "* Make a list of providers to add to the database\n",
    "* Make a deduplicated list of healthcare entities and locations from the Master Medical Staff list\n",
    "* match those against the database\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "* All entities come with a TIN; i.e. I haven't considered any rows without a TIN when working with entities.\n",
    "* All locations come with a street address; i.e. I haven't considered any rows without a street address when working with locations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Basic Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read files\n",
    "entities = pd.read_csv('kn_entities.csv')\n",
    "locations = pd.read_csv('kn_locations.csv')\n",
    "providers = pd.read_csv('kn_providers.csv')\n",
    "# For now, we need to specify the sheet names because the .xlsx file contains summary sheets \n",
    "sheets = ['CAD','CHX','GRY','KMHC','MAN','MMC','OMH','POMH'] # GO BACK TO MACK LATER; THEY DON'T HAVE NPI'S LOL\n",
    "MMS = pd.read_excel('master_medical_staff_list_200601.xlsx',sheet_name=sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, MMS is a dictionary where the sheet names are the indices and the dataframes are the values.\n",
    "The last several rows of each sheet is a summary table that is irrelevant to this project but they will be dropped as we clean the dataframe. \n",
    "\n",
    "## 1. Make a list of providers to add to the database\n",
    "\n",
    "We'll make a list of distinct providers using __first name, last name, NPI__.\n",
    "\n",
    "1. Rename three columns in `providers` (firstname, lastname, npi) so that it matches the ones in `MMS`; extract those three columns\n",
    "2. For each sheet in `MMS`, \n",
    "    1. extract the three columns `Last Name`, `First Name`, `NPI`\n",
    "    2. Find out who is in the sheet but not in `providers`\n",
    "    3. Use a sheet name to populate a new column 'Hospital affiliation'\n",
    "3. export to a new .csv file `new_providers.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. rename three columns in providers & extract those three columns\n",
    "colnames = {'Provider Name: First': 'First Name',\n",
    "           'Provider Name: Last': 'Last Name',\n",
    "           'Provider NPI': 'NPI'}\n",
    "providers = providers.rename(columns=colnames)\n",
    "providers = providers[['Last Name','First Name','NPI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (this will be a list of distinct providers who are in MMS but not in providers)\n",
    "new_providers = pd.DataFrame(columns = ['Last Name','First Name','NPI'])\n",
    "\n",
    "# 2. iterate through each affiliation \n",
    "for affiliation in MMS:\n",
    "    df = MMS[affiliation]\n",
    "    # 2A. extract the three relevant columns\n",
    "    df = df[['Last Name','First Name','NPI']]\n",
    "    # 2B. compare MMS and providers, and add any distinct provider to new_providers\n",
    "    diff = df.merge(providers,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "    diff = diff.dropna() # assuming that those without NPI or name are irrelevant...\n",
    "    # 2C. Use a sheet name to populate a new column 'Hospital affiliation'\n",
    "    diff['Affiliation'] = affiliation\n",
    "    new_providers = new_providers.append(diff)\n",
    "\n",
    "# 4. export to a new .csv file    \n",
    "new_providers.to_csv('new_providers.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make a deduplicated list of healthcare entities from the Master Medical Staff list; match with the DB\n",
    "\n",
    "Similar to #1, but for entities...\n",
    "\n",
    "1. Rename columns in the database to match MMS(`Entity TIN`-->`Tax ID`)\n",
    "2. Extract relevant parts from `MMS`\n",
    "    1. Drop all the rows that don't have a `TIN` value.\n",
    "    2. Choose columns `TIN`, `Practice`, `Practice Address`, `City, State Zip`\n",
    "    3. Compare the values with the TINs in `entities`\n",
    "    4. Add to a new dataframe (`new_entities`) whatever entities that are in MMS but not in database\n",
    "3. Export to a new .csv file (`new_entities.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Legal Name</th>\n",
       "      <th>Tax ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active Chiropractic of Cadillac</td>\n",
       "      <td>474680795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advance Pathology Services, PC</td>\n",
       "      <td>208238099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Optometry, PLLC</td>\n",
       "      <td>382137907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allergy and Asthma Specialists of Cadillac</td>\n",
       "      <td>383588887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrew S. Riemer, DO PC</td>\n",
       "      <td>383156438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Entity Legal Name     Tax ID\n",
       "0             Active Chiropractic of Cadillac  474680795\n",
       "1              Advance Pathology Services, PC  208238099\n",
       "2                    Advanced Optometry, PLLC  382137907\n",
       "3  Allergy and Asthma Specialists of Cadillac  383588887\n",
       "4                     Andrew S. Riemer, DO PC  383156438"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. rename columns in entities so that they match MMS\n",
    "colnames = {'Entity TIN': 'Tax ID'} # add more later\n",
    "entities = entities.rename(columns=colnames)\n",
    "entities = entities[['Entity Legal Name','Tax ID']]\n",
    "# typecast to str so that we can join with MMS later\n",
    "entities['Tax ID'] = entities['Tax ID'].astype(str).str[0:9]\n",
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entities = pd.DataFrame(columns = ['Practice','Tax ID','Practice Address','Zip'])\n",
    "\n",
    "# 2. extract relevant parts from MMS\n",
    "for affiliation in MMS:\n",
    "    df = MMS[affiliation]\n",
    "    # 2A. select rows that have TIN\n",
    "    df = df[df['Tax ID'].notna()]\n",
    "    # 2B. select relevant columns (Can add more later if needed)\n",
    "    df = df[['Practice','Tax ID','Practice Address','City, State Zip']]\n",
    "    if df.empty==False: # if there is any entity in MMS to check for,\n",
    "        df['Tax ID'] = df['Tax ID'].str.replace(\"-\",\"\")\n",
    "        pattern = r\"([0-9]{9})\"\n",
    "        df['TIN'] = df['Tax ID'].str.extract(pattern)\n",
    "        df = df[df['TIN'].notna()]\n",
    "        # 2C. left join, leaving only the entities that are in MMS but not in database\n",
    "        diff = df.merge(entities,indicator = True, how='left',on='Tax ID')\n",
    "        diff = diff[diff['_merge']=='left_only']\n",
    "        # 2D. append the deduplicated list of entities to the new dataframe\n",
    "        new_entities = new_entities.append(diff,ignore_index=True)\n",
    "\n",
    "new_entities = new_entities[['Practice','Tax ID','Practice Address','City, State Zip']]        \n",
    "\n",
    "# 3. export the dataframe to a new .csv file    \n",
    "new_entities.to_csv('new_entities.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISSUES:\n",
    "\n",
    "* __*`MAN` doesn't have any Tax ID recorded; does this allow me to assume that they are no new entity, or should I come up with  a way to find deduplicated entities from `MAN` too?*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Make a deduplicated list of locations from the Master Medical Staff list\n",
    "* *(__locations file is not  cleaned --> ask Adam for a new, cleaned file with no NPI?__)*\n",
    "\n",
    "\n",
    "#### GAME PLAN\n",
    "\n",
    "__From `MMS`:__\n",
    "1. Extract `Practice`, `Practice Address`, `City, State Zip` (for now) (*Drop NANs*)\n",
    "2. Split the column `City, State Zip` into `City`, `State`, and `Zip`\n",
    "3. Standaradize `Practice Address`:\n",
    "    1. Get rid of all the dots and commas\n",
    "    2. Put it in all caps\n",
    "    3. Avenue --> Ave; Street-->St; Drive-->Dr; Road--> Rd; Highway-->Hwy, etc.\n",
    "4. Rename columns: `Practice` --> `Name_MMS`; `Practice Address`--> `Address_MMS`; `Zip`-->`Zip_MMS`; etc.\n",
    "5. deduplicate\n",
    "\n",
    "__From `locations`:__\n",
    "1. Extract `Location Name`, `Physical Address: Street 1`, `Physical Address: Zip` (for now) (*Drop NANs-__if there is any NANs drop the entire row, for now__*)\n",
    "2. Standardize `Physical Address: Street 1` the same way we did for `MMS`\n",
    "3. Rename columns: `Location Name` --> `Name_DB`; `Physical Address: Street 1`--> `Address_DB`; `Physical Address: Zip`--> `Zip_DB`; etc.\n",
    "\n",
    "__With the cleaned dataframes:__\n",
    "1. Extract rows from `MMS` that are not in `locations` based on `Address_MMS`/`Address_DB` and `Zip_MMS`/`Zip_DB`\n",
    "2. Put in a new dataframe `new_locations` (*Columns: Name_MMS, Name_DB, Address, City, State, Zip (for now)*)\n",
    "3. Export the dataframe into a new .csv file `new_locations.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_DB</th>\n",
       "      <th>Address_DB</th>\n",
       "      <th>Zip_DB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active Chiropractic of Cadillac</td>\n",
       "      <td>119 N SHELBY ST</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Foot and Ankle Center Cadillac</td>\n",
       "      <td>8805 PINE RIDGE DR</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Foot and Ankle Center Manistee 118483...</td>\n",
       "      <td>1860 E PARKDALE AVE STE 2</td>\n",
       "      <td>49660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Foot and Ankle Center Traverse City</td>\n",
       "      <td>1225 FRONT ST STE 200</td>\n",
       "      <td>49684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Optometry</td>\n",
       "      <td>120 PALUSTER ST</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name_DB  \\\n",
       "0                    Active Chiropractic of Cadillac   \n",
       "1            Advanced Foot and Ankle Center Cadillac   \n",
       "2  Advanced Foot and Ankle Center Manistee 118483...   \n",
       "3       Advanced Foot and Ankle Center Traverse City   \n",
       "4                                 Advanced Optometry   \n",
       "\n",
       "                  Address_DB  Zip_DB  \n",
       "0            119 N SHELBY ST   49601  \n",
       "1         8805 PINE RIDGE DR   49601  \n",
       "2  1860 E PARKDALE AVE STE 2   49660  \n",
       "3      1225 FRONT ST STE 200   49684  \n",
       "4            120 PALUSTER ST   49601  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with DB - locations\n",
    "\n",
    "# 1. Extract `Location Name`, `Physical Address: Street 1`, `Physical Address: Zip` (for now) (*Drop NANs*)\n",
    "locations = locations[['Location Name','Physical Address: Street 1','Physical Address: Zip']]\n",
    "locations = locations.dropna(how='any')\n",
    "\n",
    "# 2. Rename columns: `Location Name` --> `Name_DB`; `Physical Address: Street 1`--> `Address_DB`; `Physical Address: Zip`--> `Zip_DB`; etc.\n",
    "newcols = {'Location Name':'Name_DB','Physical Address: Street 1':'Address_DB','Physical Address: Zip': 'Zip_DB'}\n",
    "locations = locations.rename(columns=newcols)\n",
    "\n",
    "# 3. Standardize `Address_DB` the same way we did for `MMS`\n",
    "# Get rid of all the dots commas etc etc\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('\\W',' ')\n",
    "# Also get rid of unnecessary whitespaces\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('\\s+',' ').str.strip()\n",
    "# Put it in all caps\n",
    "locations['Address_DB'] = locations['Address_DB'].str.upper()\n",
    "# Avenue --> Ave; Street-->St; Drive-->Dr; Road--> Rd; Highway-->Hwy, etc.\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('AVENUE','AVE')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('STREET','ST')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('DRIVE','DR')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('ROAD','RD')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('HIGHWAY','HWY')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('TRAIL','TR')\n",
    "locations['Address_DB'] = locations['Address_DB'].str.replace('SUITE','STE')\n",
    "\n",
    "# 4. Clean location names\n",
    "locations['Name_DB'] = locations['Name_DB'].str.replace('\\W',' ').str.replace('\\s+',' ').str.strip()\n",
    "\n",
    "# preview\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 381 entries, 0 to 25\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Name_MMS     380 non-null    object\n",
      " 1   Address_MMS  380 non-null    object\n",
      " 2   City         380 non-null    object\n",
      " 3   State        380 non-null    object\n",
      " 4   Zip_MMS      379 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 17.9+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hymnkim/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_MMS</th>\n",
       "      <th>Address_MMS</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip_MMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Munson Healthcare Cadillac Anesthesia</td>\n",
       "      <td>400 HOBART ST</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>MI</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chowdhury MD, PLLC</td>\n",
       "      <td>8795 PINE RIDGE DR</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>MI</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munson Healthcare Cadillac Cancer &amp; Infusion C...</td>\n",
       "      <td>400 HOBART ST</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>MI</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Family Practice of Cadillac, PC</td>\n",
       "      <td>827 E DIVISION</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>MI</td>\n",
       "      <td>49601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>American Healthcare Staffing Association</td>\n",
       "      <td>10126 E CHERRY BEND RD</td>\n",
       "      <td>Traverse City</td>\n",
       "      <td>MI</td>\n",
       "      <td>49684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name_MMS             Address_MMS  \\\n",
       "0              Munson Healthcare Cadillac Anesthesia           400 HOBART ST   \n",
       "2                                 Chowdhury MD, PLLC      8795 PINE RIDGE DR   \n",
       "3  Munson Healthcare Cadillac Cancer & Infusion C...           400 HOBART ST   \n",
       "4                    Family Practice of Cadillac, PC          827 E DIVISION   \n",
       "5           American Healthcare Staffing Association  10126 E CHERRY BEND RD   \n",
       "\n",
       "            City State Zip_MMS  \n",
       "0       Cadillac    MI   49601  \n",
       "2       Cadillac    MI   49601  \n",
       "3       Cadillac    MI   49601  \n",
       "4       Cadillac    MI   49601  \n",
       "5  Traverse City    MI   49684  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with MMS\n",
    "\n",
    "locations_MMS = pd.DataFrame(columns = ['Name_MMS','Address_MMS','City','State','Zip_MMS'])\n",
    "\n",
    "for affiliation in MMS:\n",
    "    df = MMS[affiliation]\n",
    "    # 1. Extract `Practice`, `Practice Address`, `City, State Zip` (for now)\n",
    "    df = df[['Practice', 'Practice Address', 'City, State Zip']]\n",
    "    # 2. Split the column `City, State Zip` into `City`, `State`, and `Zip`\n",
    "    df[['City','StateZip']] = df['City, State Zip'].str.split(',',expand=True)\n",
    "    df[['State','Zip']] = df['StateZip'].str.strip().str.split(expand=True)\n",
    "    df = df[['Practice', 'Practice Address', 'City', 'State', 'Zip']]\n",
    "        #print(df.head())\n",
    "    # 3. Standaradize `Practice Address`:\n",
    "        # 3A. Get rid of all the dots and commas etc \n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('\\W',' ')\n",
    "    # Also get rid of unnecessary whitespaces\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('\\s+',' ').str.strip()\n",
    "        # 3B. Put it in all caps\n",
    "    df['Practice Address'] = df['Practice Address'].str.upper()\n",
    "        # 3C. Avenue --> Ave; Street-->St; Drive-->Dr; Road--> Rd; Highway-->Hwy, etc.\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('AVENUE','AVE')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('STREET','ST')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('DRIVE','DR')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('ROAD','RD')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('HIGHWAY','HWY')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('TRAIL','TR')\n",
    "    df['Practice Address'] = df['Practice Address'].str.replace('SUITE','STE')\n",
    "    # 4. Rename columns: `Practice` --> `Name_MMS`; `Practice Address`--> `Address_MMS`; `Zip`-->`Zip_MMS`; etc.\n",
    "    colnames = {'Practice': 'Name_MMS', 'Practice Address': 'Address_MMS', 'Zip': 'Zip_MMS'}\n",
    "    df = df.rename(columns=colnames)\n",
    "    locations_MMS = locations_MMS.append(df)\n",
    "\n",
    "# 5. deduplicate    \n",
    "locations_MMS = locations_MMS.drop_duplicates()    \n",
    "    \n",
    "print(locations_MMS.info())    \n",
    "locations_MMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __With the cleaned dataframes:__\n",
    "# 1. Extract rows from `MMS` that are not in `locations` based on `Address_MMS`/`Address_DB` and `Zip_MMS`/`Zip_DB`\n",
    "new_locations = locations_MMS.merge(locations, indicator=True, how='outer',\n",
    "                                    left_on='Address_MMS',right_on='Address_DB')\n",
    "# new_locations = new_locations[new_locations['_merge']=='both']\n",
    "new_locations = new_locations[new_locations['_merge']=='left_only']\n",
    "#new_locations = new_locations[(new_locations['_merge']=='left_only') | (new_locations['_merge']=='right_only')]\n",
    "new_locations = new_locations.drop_duplicates(subset='Name_MMS')\n",
    "#print(new_locations.info())\n",
    "#print(new_locations.head(10))\n",
    "\n",
    "#diff = df.merge(entities,indicator = True, how='left',on='Tax ID')\n",
    "#        diff = diff[diff['_merge']=='left_only']\n",
    "\n",
    "# 2. Put in a new dataframe `new_locations` (*Columns: Name_MMS, Name_DB, Address, City, State, Zip (for now)*)\n",
    "new_locations = new_locations[['Name_MMS','Address_MMS','City','State','Zip_MMS']]\n",
    "\n",
    "# 3. Export the dataframe into a new .csv file `new_locations.csv`\n",
    "new_locations.to_csv('new_locations.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* the list is not entirely of new list bc of minor variations in the address (i.e. some have STE# or not have St, Rd, etc)\n",
    "    For example, Family Practice of Cadillac is already in the database but with a more specific address ('827 E DIVISION STE 2').\n",
    "\n",
    "\n",
    "Possible solutions:\n",
    "\n",
    "* When deduplicating `locations_MMS`, make the longest address/longest name absorb the shorter ones (i.e. leave only the entries with the most information)\n",
    "* When merging the two dataframes `locations_MMS` and `locations`, use the street address but look for 'containment', not 'exact match'. \n",
    "    1. i.e. if the entry in `Address_MMS` contains that in `Address_DB`, then either\n",
    "        1. record both address and include them \n",
    "        2. consider that location already in the DB and don't include in the unique lists\n",
    "    2. i.e. if the entry in `Address_DB` contains that in `Address_MMS`, then \n",
    "        1. consider that location already in the DB and don't include in the unique lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending Note\n",
    "\n",
    "* Run this thing but check `MACK` separately.\n",
    "* The sheet affiliated with `MAN` doesn't have any Tax ID recorded for any of the practices; hence no entities were added from this affiliation. If we want to get entities from `MAN` we should come up with some other method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *++++below are just random stuff i've been trying++++*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate a new boolean column 'MMS>DB' that says 'True' if MMS address contains DB address\n",
    "locations_MMS = locations_MMS[['Name_MMS','Address_MMS','City','State','Zip_MMS']].dropna(how='any')\n",
    "locations_MMS['MMS>DB'] = False\n",
    "\n",
    "# for every row in Address_MMS, check if there is a substring in Address_DB\n",
    "\n",
    "for i in range(locations_MMS.shape[0]):\n",
    "    address = str(locations_MMS.iloc[i,1])\n",
    "    #print(address)\n",
    "    for item in locations['Address_DB']:\n",
    "        #print(item_DB)\n",
    "        if str(item) in address:\n",
    "            locations_MMS.loc[i,'Address_DB'] = item\n",
    "            locations_MMS.loc[i,'MMS>DB'] = True\n",
    "            #print('Found it!')\n",
    "            break  \n",
    "\n",
    "# take a look at locations that are in MMS but not in DB\n",
    "print(locations_MMS['MMS>DB'].value_counts(dropna=False))\n",
    "locations_MMS[locations_MMS['MMS>DB']==True].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate a new boolean column 'DB>MMS' that says 'True' if DB address contains MMS address\n",
    "locations = locations.dropna(how='any')\n",
    "locations['DB>MMS'] = False\n",
    "\n",
    "#for address_DB in locations['Address_DB'], check if there is a substring in Address_MMS\n",
    "for i in range (locations.shape[0]):\n",
    "    item = str(locations.iloc[i,1])\n",
    "    for address in locations_MMS['Address_MMS']:\n",
    "        if str(address) in item:\n",
    "            locations.loc[i,'Address_MMS'] = address\n",
    "            locations.loc[i,'DB>MMS'] = True\n",
    "            break\n",
    "\n",
    "# take a look at locations that are in MMS but not in DB\n",
    "#print(locations[locations['DB>MMS']==False])\n",
    "print(locations['DB>MMS'].value_counts(dropna=False))\n",
    "locations.head(10)\n",
    "locations[locations['DB>MMS']==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer merge with the street address\n",
    "new_locations = locations_MMS.merge(locations, indicator=True, how='outer',\n",
    "                                    left_on='Address_MMS',right_on='Address_DB')\n",
    "# new_locations = new_locations[new_locations['_merge']=='both']\n",
    "new_locations = new_locations[new_locations['_merge']=='left_only']\n",
    "#new_locations = new_locations[(new_locations['_merge']=='left_only') | (new_locations['_merge']=='right_only')]\n",
    "new_locations = new_locations.drop_duplicates(subset='Name_MMS')\n",
    "new_locations.info()\n",
    "new_locations.head(10)\n",
    "\n",
    "#diff = df.merge(entities,indicator = True, how='left',on='Tax ID')\n",
    "#        diff = diff[diff['_merge']=='left_only']\n",
    "# 2. Put in a new dataframe `new_locations` (*Columns: Name_MMS, Name_DB, Address, City, State, Zip (for now)*)\n",
    "# 3. Export the dataframe into a new .csv file `new_locations.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "There is a way to compute the 'distance' between the two strings (i.e. [Levinshtein distance](https://www.datacamp.com/community/tutorials/fuzzy-string-python)) and choose a certain row if the distance between the two strings is short enough.\n",
    "There's also the `fuzzywuzzy` package that computes the 'fuzz ratio' - how similar the two strings are. Great thing about this one is that it supports partial ratio (like a search) and mixed orders (i.e. 'US vs Canada' and 'Canada vs US' will have a token ratio of 100%).\n",
    "\n",
    "But since we are looking for a definite solution (i.e. would rather extract more information than to miss some) I didn't use these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just...exploring. random notes.\n",
    "\n",
    "#### MMS First Impression\n",
    "* The sheet `MACK` is in a format that is different from all other sheets for individual hospitals. Why...\n",
    "* For all other sheets, there is a mini-table at the bottom with sum summary numbers.\n",
    "* Minor variations in `Practice Address` (e.g. 'St' vs 'St.' vs 'Street'; 'Trail vs 'Tr.'; 'Carmel St.' vs 'S. Carmel St.')\n",
    "* `Specialty` seems to be clean and standardized\n",
    "* Ooh there is a column `Primary Facility` that has the hospital code as its value; I can download everything (except `MACK`) into one dataframe. \n",
    "    * not all of these will be useful\n",
    "* I'm just going to believe the provider names, NPI, Tax ID, and phone numbers.\n",
    "\n",
    "__*Practice column is both a location and an entity.__ \n",
    "\n",
    "#### Providers list First Impression\n",
    "* `Provider Name: Last`, `Provider Name: First`, and `Provider NPI` will be useful.\n",
    "* `Provider Primary Specialty` has some empty cells but still usable; just need to use in conjunction with other things\n",
    "* There are subtle variations between `Primary Employer`(healthcare entity - TIN) and `Primary Practice Location` (healthcare location - Group NPI); also some are empty cells.\n",
    "    * these are going away in the next couple of weeks, though.  \n",
    "\n",
    "#### Locations list First Impression\n",
    "* pretty messy...\n",
    "* `Location Name` is almost clean; some entries have NPI attached at the end but we can remove it.\n",
    "* Addresses are all messed up. Most have the physical address in full (`Physical Address`), but not all. Some entries don't have physical address but only state and zip code; Some have state code under the column `Physical Address: City`; the only column without any missing values seems to be `Physical Address: Zip`. \n",
    "    * __Adam's note: throw these out :)__ \n",
    "* There are information about latitudes, longitudes, and phone numbers; but they aren't available for all locations.\n",
    "\n",
    "#### Entities list First Impression\n",
    "* `Entity Legal Name` looks nice and clean. No empty cells; no weird variations (at least on the first look). This could be used as a standard.\n",
    "* There are many entities that literally have no information other than their name and TIN...what to do? \n",
    "    * probably \n",
    "* There's the `Billing Address` and there's the `Mailing Address`, and they are _different_. Geez\n",
    "* The only columns that are fully populated are `Entity`,`Entity Legal Name`, and `Entity TIN`. If I am going to use any other columns I would have to be careful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
